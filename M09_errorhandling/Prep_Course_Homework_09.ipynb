{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manejo de errores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Con la clase creada en el módulo 7, tener en cuenta diferentes casos en que el código pudiera arrojar error. Por ejemplo, en la creación del objeto recibimos una lista de números enteros pero ¿qué pasa si se envía otro tipo de dato?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:/Users/manue/Desktop/Facultad/Henry/Python-Prep/M09_errorhandling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Ejercicio9 as Ej9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "('El argumento introducido es incorrecto, se ha introducido un ', <class 'str'>, 'y se esperaba una lista')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test\u001b[38;5;241m=\u001b[39m\u001b[43mEj9\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModulo7\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHola\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\manue\\Desktop\\Facultad\\Henry\\Python-Prep\\M09_errorhandling\\Ejercicio9.py:6\u001b[0m, in \u001b[0;36mModulo7.__init__\u001b[1;34m(self, lista)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mtype\u001b[39m(lista)\u001b[38;5;241m!=\u001b[39m\u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlista\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m----> 6\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEl argumento introducido es incorrecto, se ha introducido un \u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;28mtype\u001b[39m(lista), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my se esperaba una lista\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlista\u001b[38;5;241m=\u001b[39mlista\n",
      "\u001b[1;31mValueError\u001b[0m: ('El argumento introducido es incorrecto, se ha introducido un ', <class 'str'>, 'y se esperaba una lista')"
     ]
    }
   ],
   "source": [
    "test=Ej9.Modulo7(\"Hola\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=Ej9.Modulo7([1,2,3,4,5,6,7,8,9,1,2,1])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) En la función que hace la conversión de grados, validar que los parámetros enviados sean los esperados, de no serlo, informar cuáles son los valores esperados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Ejercicio9' from 'c:\\\\Users\\\\manue\\\\Desktop\\\\Facultad\\\\Henry\\\\Python-Prep\\\\M09_errorhandling\\\\Ejercicio9.py'>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(Ej9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El parametro enviado para el origen no es valido, debe ser: ['C', 'F', 'K']\n"
     ]
    }
   ],
   "source": [
    "test=Ej9.Modulo7([1,2,3,4,5,6,7,8,9,1,2,1])\n",
    "test.conver(\"D\",\"F\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Importar el modulo \"unittest\" y crear los siguientes casos de pruebas sobre la clase utilizada en el punto 2<br>\n",
    "Creacion del objeto incorrecta<br>\n",
    "Creacion correcta del objeto<br>\n",
    "Metodo valor_modal()<br>\n",
    "\n",
    "Se puede usar \"raise ValueError()\" en la creación de la clase para verificar el error. Investigar sobre esta funcionalidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "class Pruebas(unittest.TestCase):\n",
    "    def test_objeto_incorrecto(self):\n",
    "        parametro=\"hola\"\n",
    "        self.assertRaises(ValueError,Ej9.Modulo7,parametro)\n",
    "\n",
    "    def test_objeto_correcto(self):\n",
    "        parametro=[1,2,3,4,5,6,7,8,9,1,2,1]\n",
    "        test2=Ej9.Modulo7(parametro)\n",
    "        self.assertEqual(test2.lista,parametro)\n",
    "\n",
    "    def test_modal(self):\n",
    "        parametro=[1,2,3,4,5,6,7,8,9,1,2,1]\n",
    "        resultado=(1,3)\n",
    "        test3=Ej9.Modulo7(parametro)\n",
    "        modal=test3.repe()\n",
    "        self.assertEqual(modal,resultado)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_modal (__main__.Pruebas) ... ok\n",
      "test_objeto_correcto (__main__.Pruebas) ... ok\n",
      "test_objeto_incorrecto (__main__.Pruebas) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.004s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x1919af1ee00>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Probar una creación incorrecta y visualizar la salida del \"raise\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "('El argumento introducido es incorrecto, se ha introducido un ', <class 'str'>, 'y se esperaba una lista')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test\u001b[38;5;241m=\u001b[39m\u001b[43mEj9\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModulo7\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHola\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\manue\\Desktop\\Facultad\\Henry\\Python-Prep\\M09_errorhandling\\Ejercicio9.py:6\u001b[0m, in \u001b[0;36mModulo7.__init__\u001b[1;34m(self, lista)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mtype\u001b[39m(lista)\u001b[38;5;241m!=\u001b[39m\u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlista\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m----> 6\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEl argumento introducido es incorrecto, se ha introducido un \u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;28mtype\u001b[39m(lista), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my se esperaba una lista\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlista\u001b[38;5;241m=\u001b[39mlista\n",
      "\u001b[1;31mValueError\u001b[0m: ('El argumento introducido es incorrecto, se ha introducido un ', <class 'str'>, 'y se esperaba una lista')"
     ]
    }
   ],
   "source": [
    "test=Ej9.Modulo7(\"Hola\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Agregar casos de pruebas para el método verifica_primos() realizando el cambio en la clase, para que devuelva una lista de True o False en función de que el elemento en la posisicón sea o no primo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Ejercicio9' from 'c:\\\\Users\\\\manue\\\\Desktop\\\\Facultad\\\\Henry\\\\Python-Prep\\\\M09_errorhandling\\\\Ejercicio9.py'>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(Ej9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prueba2 (unittest.TestCase):\n",
    "    def test_Verif_primos(self):\n",
    "        parametro=[1,2,3,4,5,6]\n",
    "        resultado_esperado=[True,True,True,False,True,False]\n",
    "        test4=Ej9.Modulo7(parametro)\n",
    "        resultado=test4.verif_primo()\n",
    "        self.assertEqual(resultado,resultado_esperado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_Verif_primos (__main__.Prueba2) ... ok\n",
      "test_modal (__main__.Pruebas) ... ok\n",
      "test_objeto_correcto (__main__.Pruebas) ... ok\n",
      "test_objeto_incorrecto (__main__.Pruebas) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.010s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x1919b7ddbd0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Agregar casos de pruebas para el método conversion_grados()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Ejercicio9' from 'c:\\\\Users\\\\manue\\\\Desktop\\\\Facultad\\\\Henry\\\\Python-Prep\\\\M09_errorhandling\\\\Ejercicio9.py'>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(Ej9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prueba4(unittest.TestCase):\n",
    "    def test_verif_conver1(self):\n",
    "        parametros=[1,2,3,4,5]\n",
    "        test5=Ej9.Modulo7(parametros)\n",
    "        resultados_esperados=[33.8,35.6,37.4,39.2,41.0]\n",
    "        resultados=test5.conver(\"C\",\"F\")\n",
    "        self.assertEqual(resultados,resultados_esperados)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_Verif_primos (__main__.Prueba2) ... ok\n",
      "test_verif_conver1 (__main__.Prueba4) ... ok\n",
      "test_modal (__main__.Pruebas) ... ok\n",
      "test_objeto_correcto (__main__.Pruebas) ... ok\n",
      "test_objeto_incorrecto (__main__.Pruebas) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.007s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x1919be81690>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Agregar casos de pruebas para el método factorial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Ejercicio9' from 'c:\\\\Users\\\\manue\\\\Desktop\\\\Facultad\\\\Henry\\\\Python-Prep\\\\M09_errorhandling\\\\Ejercicio9.py'>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(Ej9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prueba5(unittest.TestCase):\n",
    "    def test_verif_factorial(self):\n",
    "        parametros=[1,2,3,4,5]\n",
    "        test6=Ej9.Modulo7(parametros)\n",
    "        resultados_esperados=[1,2,6,24,120]\n",
    "        resultados=test6.factorial()\n",
    "        self.assertEqual(resultados,resultados_esperados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_Verif_primos (__main__.Prueba2) ... ok\n",
      "test_verif_conver1 (__main__.Prueba4) ... ok\n",
      "test_verif_factorial (__main__.Prueba5) ... ok\n",
      "test_modal (__main__.Pruebas) ... ok\n",
      "test_objeto_correcto (__main__.Pruebas) ... ok\n",
      "test_objeto_incorrecto (__main__.Pruebas) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.013s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x1919b6398a0>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c85384e4cb51c8b72350f3a8712cc8351fdc3955e32a27f9b60c6242ab125f01"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
